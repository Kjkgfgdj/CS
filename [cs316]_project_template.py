# -*- coding: utf-8 -*-
"""[CS316] Project Template.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E9YwMPACq1AGh02QuouOvYk9ATolfMnr

# CS316 Project - Introduction to AI and Data Science

## Group Information
---
**Group Members:**
* Name 1 - Student ID
* Name 2 - Student ID
* [Add more members as needed]

**Project Topic:** [Your sustainability topic]

## Section 1: Problem Definition
---
### Instructions
In this section, you must:
1. Define your research questions (minimum 3 questions)
2. Explain how your project aligns with UN Sustainable Development Goals (SDGs)
3. Identify the specific problem you're addressing
4. Describe the potential impact of your solution

**Research Questions Example Format:**
* RQ1: How does [variable X] affect [sustainability outcome Y]?
* RQ2: What is the relationship between [factor A] and [factor B] in [your domain]?
* RQ3: Can we predict [sustainability metric] using [available data]?
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Set random seed for reproducibility
np.random.seed(42)

"""## Section 2: Data Collection & Preparation
---
### Instructions
Document your data source(s) and prepare your dataset:
1. **Data Source Documentation:**
   * Dataset name and source
   * Time period covered
   * Number of records and features
   * Data collection methodology

2. **Initial Data Assessment:**
   * Run and document basic statistics
   * Check for missing values
   * Identify potential data quality issues
"""

#Load your dataset
def load_dataset():
    """
    Load the dataset and perform initial assessment
    """
    # Load your data
    df = pd.read_csv('your_dataset.csv')

    # Display basic information
    print("Dataset Shape:", df.shape)
    print("\nDataset Info:")
    print(df.info())
    print("\nMissing Values:")
    print(df.isnull().sum())

    return df

"""## Section 3: Exploratory Data Analysis (EDA)
---
### Instructions
Task. Understand your data patterns and perform comprehensive EDA to understand your data:

**1. Required Analyses:**
   * Descriptive Statistics
   * Univariate analysis for each key variable
   * Bivariate analysis between target and features
   * Correlation analysis
   * Time series patterns (if applicable)

**2. Required Visualizations (minimum 5):**
   * Distribution plots
   * Correlation heatmap
   * Feature relationships
   * Target variable analysis
   * Time-based trends (if applicable)
"""

def perform_eda(df):
    """
    Conduct exploratory data analysis
    """
    # 1. Univariate Analysis

    # 2. Bivariate Analysis

    # 3. Correlation Analysis

    # 4. Custom Analysis for Your Topic

"""## Section 4: Feature Engineering
---
### Instructions
Document your feature engineering process:

**1. Feature Creation:**
   * Create new features based on domain knowledge
   * Document the rationale for each new feature
   * Validate feature usefulness

**2. Feature Selection:**
   * Identify most important features
   * Remove redundant features
   * Document selection criteria
"""

def engineer_features(df):
    """
    Create and select features
    """
    # 1. Create new features

    # 2. Feature selection

    # 3. Document feature importance

"""## Section 5: Model Development
---
### Instructions
Develop and train your models:

**1. Required Steps:**
   * Split data into training and testing sets
   * Implement at least 3 different models
   * Document model selection rationale
   * Implement cross-validation

**2. Memory Optimization Requirements:**
   * Use appropriate data types
   * Implement batch processing if needed
   * Document memory usage
"""

def train_models(X_train, X_test, y_train, y_test):
    """
    Train and compare different models
    """
    models = {
        'model1_name': model1,
        'model2_name': model2,
        'model3_name': model3
    }

"""## Section 6: Model Evaluation
---
### Instructions
Evaluate your models thoroughly:

**1. Required Metrics:**
   * Accuracy/RMSE (depending on problem type)
   * Precision, Recall, F1-Score (for classification)
   * Cross-validation scores
   * Model comparison analysis

**2. Required Visualizations:**
   * Confusion matrix (for classification)
   * ROC curves (for classification)
   * Prediction vs Actual plots (for regression)
   * Feature importance plots
"""

def evaluate_models(models, X_test, y_test):
    """
    Evaluate model performance
    """
    # Calculate and display all required metrics
    # Generate required visualizations

"""## Section 7: Results & Sustainability Impact
---
### Instructions
Document your findings and impact:

**1. Required Components:**
   * Answer each research question with evidence
   * Quantify sustainability impact
   * Discuss limitations
   * Propose future improvements

**2. Impact Assessment:**
   * Environmental impact
   * Social impact
   * Economic impact
   * SDG alignment evidence
"""

def document_impact():
    """
    Document sustainability impact
    """
    # Quantify and document impacts
    # Create impact visualizations

"""## Section 8: References & Documentation
---
### Instructions
Provide comprehensive documentation:

**1. Required Elements:**
   * All data sources
   * External libraries used
   * Academic references
   * Code documentation
   * Installation/runtime instructions

**2. GitHub Requirements:**
   * README file
   * Requirements.txt
   * Code comments
   * Usage examples

**Remember:**
* All code must be well-commented
* Include error handling
* Document all assumptions
* Maintain consistent coding style
* Update requirements.txt as you add libraries
"""

